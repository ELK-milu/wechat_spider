#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®ä¿¡å…¬ä¼—å·çˆ¬è™«ä¾¿æ·å‡½æ•°åº“
åŸºäºç”¨æˆ·ä¿®æ­£ä»£ç ï¼Œæä¾›å„ç§ä¾¿æ·çš„ä¸‹è½½å‡½æ•°
"""

from wechatspider_fixed import WeChatSpider
import datetime

# ============== å•è´¦å·ä¸‹è½½å‡½æ•° ==============

def download_latest(account_name, use_selenium=False):
    """
    ä¸‹è½½æŒ‡å®šå…¬ä¼—å·çš„æœ€æ–°ä¸€ç¯‡æ–‡ç« 
    
    Args:
        account_name (str): å…¬ä¼—å·åç§° ("ç²¤æ”¿ä¼šè®¡", "ç‘å¹¸å’–å•¡", "å¨ç§‘å…ˆè¡Œ")
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Seleniumï¼ˆé»˜è®¤Falseï¼Œä½¿ç”¨requestsæ›´ç¨³å®šï¼‰
    
    Returns:
        dict: æ–‡ç« ä¿¡æ¯ï¼Œå¤±è´¥è¿”å›None
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ã€{account_name}ã€‘æœ€æ–°æ–‡ç« ...")
    
    spider = WeChatSpider()
    try:
        article = spider.crawl_latest_article(
            use_selenium=use_selenium,
            account_name=account_name
        )
        return article
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return None
    finally:
        spider.close_driver()

def download_recent_week(account_name, max_articles=10, use_selenium=False):
    """
    ä¸‹è½½æŒ‡å®šå…¬ä¼—å·æœ€è¿‘ä¸€å‘¨çš„æ–‡ç« 
    
    Args:
        account_name (str): å…¬ä¼—å·åç§°
        max_articles (int): æœ€å¤§æ–‡ç« æ•°é‡
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        list: æ–‡ç« åˆ—è¡¨
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ã€{account_name}ã€‘æœ€è¿‘ä¸€å‘¨æ–‡ç« ï¼Œæœ€å¤š{max_articles}ç¯‡...")
    
    spider = WeChatSpider()
    try:
        articles = spider.crawl_recent_articles(
            days_back=7,
            max_articles=max_articles,
            use_selenium=use_selenium,
            account_name=account_name
        )
        if articles:
            spider.save_to_json(account_name=account_name)
            spider.save_to_excel(account_name=account_name)
        return articles
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return []
    finally:
        spider.close_driver()

def download_recent_month(account_name, max_articles=50, use_selenium=False):
    """
    ä¸‹è½½æŒ‡å®šå…¬ä¼—å·æœ€è¿‘ä¸€ä¸ªæœˆçš„æ–‡ç« 
    
    Args:
        account_name (str): å…¬ä¼—å·åç§°
        max_articles (int): æœ€å¤§æ–‡ç« æ•°é‡
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        list: æ–‡ç« åˆ—è¡¨
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ã€{account_name}ã€‘æœ€è¿‘ä¸€ä¸ªæœˆæ–‡ç« ï¼Œæœ€å¤š{max_articles}ç¯‡...")
    
    spider = WeChatSpider()
    try:
        articles = spider.crawl_recent_articles(
            days_back=30,
            max_articles=max_articles,
            use_selenium=use_selenium,
            account_name=account_name
        )
        if articles:
            spider.save_to_json(account_name=account_name)
            spider.save_to_excel(account_name=account_name)
        return articles
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return []
    finally:
        spider.close_driver()

def download_recent_quarter(account_name, max_articles=100, use_selenium=False):
    """
    ä¸‹è½½æŒ‡å®šå…¬ä¼—å·æœ€è¿‘ä¸‰ä¸ªæœˆçš„æ–‡ç« 
    
    Args:
        account_name (str): å…¬ä¼—å·åç§°
        max_articles (int): æœ€å¤§æ–‡ç« æ•°é‡
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        list: æ–‡ç« åˆ—è¡¨
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ã€{account_name}ã€‘æœ€è¿‘ä¸‰ä¸ªæœˆæ–‡ç« ï¼Œæœ€å¤š{max_articles}ç¯‡...")
    
    spider = WeChatSpider()
    try:
        articles = spider.crawl_recent_articles(
            days_back=90,
            max_articles=max_articles,
            use_selenium=use_selenium,
            account_name=account_name
        )
        if articles:
            spider.save_to_json(account_name=account_name)
            spider.save_to_excel(account_name=account_name)
        return articles
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return []
    finally:
        spider.close_driver()

def download_custom_period(account_name, days_back, max_articles=50, use_selenium=False):
    """
    ä¸‹è½½æŒ‡å®šå…¬ä¼—å·è‡ªå®šä¹‰æ—¶é—´æ®µçš„æ–‡ç« 
    
    Args:
        account_name (str): å…¬ä¼—å·åç§°
        days_back (int): å‘å‰è¿½æº¯å¤©æ•°
        max_articles (int): æœ€å¤§æ–‡ç« æ•°é‡
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        list: æ–‡ç« åˆ—è¡¨
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ã€{account_name}ã€‘æœ€è¿‘{days_back}å¤©æ–‡ç« ï¼Œæœ€å¤š{max_articles}ç¯‡...")
    
    spider = WeChatSpider()
    try:
        articles = spider.crawl_recent_articles(
            days_back=days_back,
            max_articles=max_articles,
            use_selenium=use_selenium,
            account_name=account_name
        )
        if articles:
            spider.save_to_json(account_name=account_name)
            spider.save_to_excel(account_name=account_name)
        return articles
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return []
    finally:
        spider.close_driver()

# ============== å¤šè´¦å·ä¸‹è½½å‡½æ•° ==============

def download_all_latest(use_selenium=False):
    """
    ä¸‹è½½æ‰€æœ‰å…¬ä¼—å·çš„æœ€æ–°æ–‡ç« 
    
    Args:
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        list: æ‰€æœ‰æ–‡ç« åˆ—è¡¨
    """
    print("ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰å…¬ä¼—å·æœ€æ–°æ–‡ç« ...")
    
    spider = WeChatSpider()
    try:
        articles = spider.crawl_all_accounts_latest(use_selenium=use_selenium)
        return articles
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return []
    finally:
        spider.close_driver()

def download_all_recent_week(max_articles_per_account=10, use_selenium=False):
    """
    ä¸‹è½½æ‰€æœ‰å…¬ä¼—å·æœ€è¿‘ä¸€å‘¨çš„æ–‡ç« 
    
    Args:
        max_articles_per_account (int): æ¯ä¸ªå…¬ä¼—å·æœ€å¤§æ–‡ç« æ•°
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        dict: {å…¬ä¼—å·åç§°: [æ–‡ç« åˆ—è¡¨]}
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰å…¬ä¼—å·æœ€è¿‘ä¸€å‘¨æ–‡ç« ï¼Œæ¯ä¸ªè´¦å·æœ€å¤š{max_articles_per_account}ç¯‡...")
    
    spider = WeChatSpider()
    results = {}
    
    try:
        for account_name in spider.FAKEIDS.keys():
            print(f"\nğŸ“± å¤„ç†å…¬ä¼—å·: {account_name}")
            articles = spider.crawl_recent_articles(
                days_back=7,
                max_articles=max_articles_per_account,
                use_selenium=use_selenium,
                account_name=account_name
            )
            results[account_name] = articles
            
            if articles:
                spider.save_to_json(account_name=account_name)
                spider.save_to_excel(account_name=account_name)
            
            # é‡ç½®articlesé¿å…æ··æ·†
            spider.articles = []
        
        return results
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return {}
    finally:
        spider.close_driver()

def download_all_recent_month(max_articles_per_account=50, use_selenium=False):
    """
    ä¸‹è½½æ‰€æœ‰å…¬ä¼—å·æœ€è¿‘ä¸€ä¸ªæœˆçš„æ–‡ç« 
    
    Args:
        max_articles_per_account (int): æ¯ä¸ªå…¬ä¼—å·æœ€å¤§æ–‡ç« æ•°
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        dict: {å…¬ä¼—å·åç§°: [æ–‡ç« åˆ—è¡¨]}
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰å…¬ä¼—å·æœ€è¿‘ä¸€ä¸ªæœˆæ–‡ç« ï¼Œæ¯ä¸ªè´¦å·æœ€å¤š{max_articles_per_account}ç¯‡...")
    
    spider = WeChatSpider()
    results = {}
    
    try:
        for account_name in spider.FAKEIDS.keys():
            print(f"\nğŸ“± å¤„ç†å…¬ä¼—å·: {account_name}")
            articles = spider.crawl_recent_articles(
                days_back=30,
                max_articles=max_articles_per_account,
                use_selenium=use_selenium,
                account_name=account_name
            )
            results[account_name] = articles
            
            if articles:
                spider.save_to_json(account_name=account_name)
                spider.save_to_excel(account_name=account_name)
            
            # é‡ç½®articlesé¿å…æ··æ·†
            spider.articles = []
        
        return results
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return {}
    finally:
        spider.close_driver()

# ============== ç‰¹æ®ŠåŠŸèƒ½å‡½æ•° ==============

def download_by_keyword(account_name, keyword, days_back=30, max_articles=20, use_selenium=False):
    """
    ä¸‹è½½åŒ…å«ç‰¹å®šå…³é”®è¯çš„æ–‡ç« ï¼ˆåœ¨æ ‡é¢˜ä¸­æœç´¢ï¼‰
    
    Args:
        account_name (str): å…¬ä¼—å·åç§°
        keyword (str): æœç´¢å…³é”®è¯
        days_back (int): å‘å‰è¿½æº¯å¤©æ•°
        max_articles (int): æœ€å¤§æ–‡ç« æ•°é‡
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        list: åŒ¹é…çš„æ–‡ç« åˆ—è¡¨
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ã€{account_name}ã€‘åŒ…å«å…³é”®è¯'{keyword}'çš„æ–‡ç« ...")
    
    spider = WeChatSpider()
    try:
        # å…ˆè·å–æ‰€æœ‰æ–‡ç« 
        all_articles = spider.crawl_recent_articles(
            days_back=days_back,
            max_articles=max_articles,
            use_selenium=use_selenium,
            account_name=account_name
        )
        
        # è¿‡æ»¤åŒ…å«å…³é”®è¯çš„æ–‡ç« 
        matched_articles = []
        for article in all_articles:
            if keyword.lower() in article['title'].lower():
                matched_articles.append(article)
        
        print(f"ğŸ¯ åœ¨{len(all_articles)}ç¯‡æ–‡ç« ä¸­æ‰¾åˆ°{len(matched_articles)}ç¯‡åŒ…å«å…³é”®è¯'{keyword}'çš„æ–‡ç« ")
        
        if matched_articles:
            # ä¿å­˜è¿‡æ»¤åçš„ç»“æœ
            spider.articles = matched_articles
            spider.save_to_json(account_name=account_name)
            spider.save_to_excel(account_name=account_name)
        
        return matched_articles
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return []
    finally:
        spider.close_driver()

def download_top_articles(account_name, top_n=5, days_back=30, use_selenium=False):
    """
    ä¸‹è½½æŒ‡å®šå…¬ä¼—å·æœ€è¿‘çš„å‰Nç¯‡æ–‡ç« ï¼ˆæŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼‰
    
    Args:
        account_name (str): å…¬ä¼—å·åç§°
        top_n (int): å‰Nç¯‡æ–‡ç« 
        days_back (int): å‘å‰è¿½æº¯å¤©æ•°
        use_selenium (bool): æ˜¯å¦ä½¿ç”¨Selenium
    
    Returns:
        list: å‰Nç¯‡æ–‡ç« åˆ—è¡¨
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ã€{account_name}ã€‘æœ€è¿‘{days_back}å¤©çš„å‰{top_n}ç¯‡æ–‡ç« ...")
    
    spider = WeChatSpider()
    try:
        articles = spider.crawl_recent_articles(
            days_back=days_back,
            max_articles=top_n,
            use_selenium=use_selenium,
            account_name=account_name
        )
        
        if articles:
            spider.save_to_json(account_name=account_name)
            spider.save_to_excel(account_name=account_name)
        
        return articles
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return []
    finally:
        spider.close_driver()

def get_article_summary(account_name, days_back=7):
    """
    è·å–æŒ‡å®šå…¬ä¼—å·çš„æ–‡ç« æ•°é‡ç»Ÿè®¡ï¼ˆä¸ä¸‹è½½å†…å®¹ï¼Œåªç»Ÿè®¡ï¼‰
    
    Args:
        account_name (str): å…¬ä¼—å·åç§°
        days_back (int): å‘å‰è¿½æº¯å¤©æ•°
    
    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    print(f"ğŸš€ å¼€å§‹ç»Ÿè®¡ã€{account_name}ã€‘æœ€è¿‘{days_back}å¤©çš„æ–‡ç« æ•°é‡...")
    
    spider = WeChatSpider()
    try:
        # è·å–æ–‡ç« é“¾æ¥ï¼ˆä¸è·å–è¯¦ç»†å†…å®¹ï¼‰
        links = []
        page = 0
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days_back)
        
        while True:
            page_links = spider.fetch_article_links(begin=page*5, count=5, account_name=account_name)
            
            if not page_links:
                break
            
            for link in page_links:
                pub_dt = datetime.datetime.strptime(link["pub_time"], "%Y-%m-%d %H:%M:%S")
                if pub_dt >= cutoff_date:
                    links.append(link)
                else:
                    break
            
            page += 1
            if page > 20:  # é˜²æ­¢æ— é™å¾ªç¯
                break
        
        summary = {
            "account_name": account_name,
            "days_back": days_back,
            "total_articles": len(links),
            "latest_article": links[0]["title"] if links else "æ— æ–‡ç« ",
            "latest_pub_time": links[0]["pub_time"] if links else "æ— å‘å¸ƒæ—¶é—´",
            "articles": [{"title": l["title"], "pub_time": l["pub_time"]} for l in links]
        }
        
        print(f"ğŸ“Š ç»Ÿè®¡å®Œæˆï¼šæœ€è¿‘{days_back}å¤©å…±{len(links)}ç¯‡æ–‡ç« ")
        return summary
        
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡å¤±è´¥: {e}")
        return {}
    finally:
        spider.close_driver()

# ============== ä¾¿æ·åˆ«åå‡½æ•° ==============

# å•è´¦å·ä¾¿æ·å‡½æ•°


# ============== æµ‹è¯•å‡½æ•° ==============

def test_all_functions():
    """æµ‹è¯•æ‰€æœ‰å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ‰€æœ‰å‡½æ•°...")
    
    # æµ‹è¯•å•è´¦å·å‡½æ•°
    print("\n" + "="*50)
    print("æµ‹è¯•å•è´¦å·å‡½æ•°")
    print("="*50)

    recentweek = download_recent_week("å¨ç§‘å…ˆè¡Œ")
    if recentweek:
        print(f"âœ… è¿‘ä¸€å‘¨æ–‡ç« æµ‹è¯•æˆåŠŸï¼Œå…±{len(recentweek)}ç¯‡")
    
    # # æµ‹è¯•ä¸‹è½½æœ€æ–°æ–‡ç« 
    # latest = download_latest("å¨ç§‘å…ˆè¡Œ")
    # if latest:
    #     print(f"âœ… æœ€æ–°æ–‡ç« æµ‹è¯•æˆåŠŸ: {latest['title']}")
    #
    # # æµ‹è¯•å¤šè´¦å·å‡½æ•°
    # print("\n" + "="*50)
    # print("æµ‹è¯•å¤šè´¦å·å‡½æ•°")
    # print("="*50)
    #
    # # æµ‹è¯•ä¸‹è½½æ‰€æœ‰æœ€æ–°æ–‡ç« 
    # all_latest = download_all_latest()
    # if all_latest:
    #     print(f"âœ… æ‰€æœ‰æœ€æ–°æ–‡ç« æµ‹è¯•æˆåŠŸï¼Œå…±{len(all_latest)}ç¯‡")
    #
    # # æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
    # print("\n" + "="*50)
    # print("æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½")
    # print("="*50)
    #
    # summary = get_article_summary("å¨ç§‘å…ˆè¡Œ", days_back=7)
    # if summary:
    #     print(f"âœ… ç»Ÿè®¡æµ‹è¯•æˆåŠŸ: {summary['total_articles']}ç¯‡æ–‡ç« ")
    #
    # print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_all_functions() 